{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load features\n",
    "import pickle\n",
    "features = pickle.load( open( \"Onehotfeatures.pkl\", \"rb\" ) )\n",
    "\n",
    "# load associated targets\n",
    "from numpy import load\n",
    "y = load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose features and prepare data for scikit-learn prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep features of interest\n",
    "imp_feature = ['User_ID', 'Product_ID', 'Gender_Prod_cat123']\n",
    "# imp_feature = ['User_ID', 'Product_ID', 'Gender', 'Prod_cat123']\n",
    "# only keep corresponding features\n",
    "X_features = tuple(f[0] for f in features if f[1] in imp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550071, 9996), scipy.sparse.coo.coo_matrix)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X = hstack( X_features )\n",
    "X.shape, type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest - Grid search (Takes too long on my machine, think days)\n",
    "\n",
    "On top of decision tree hyperparameters, Random forest adds the following hyperparameters:\n",
    "1. **n_estimators**, number of trees in forest\n",
    "2. **bootstrap**, adds extra randomness (sample data with replacement)\n",
    "\n",
    "[Sklearn Random Forest Regressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PARAMETERS VALUES FOR GRID SEARCH\n",
    "import numpy as np\n",
    "\n",
    "depth_arr = np.array([ 10**x for x in range(2,4+1)])\n",
    "# depth_arr = np.array([ x for x in range(100,1000+100, 100)])\n",
    "\n",
    "min_leaf_arr = np.array([ x+1 for x in range(0, 100+10, 10)])\n",
    "min_leaf_arr[0]=1\n",
    "# min_leaf_arr = np.array([ x for x in range(0, 20+1, 1)])\n",
    "# min_leaf_arr = min_leaf_arr[1:]\n",
    "\n",
    "est_arr = np.array([ 200, 500, 3000, 5000 ])\n",
    "\n",
    "param_grid_rfr = [{'max_depth': depth_arr, 'min_samples_leaf': min_leaf_arr, 'n_estimators': est_arr}]\n",
    "param_grid_rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random forest are bags of decision trees, running this grid will take DAYS on a quad-core i7!\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=10,\\\n",
    "                            min_samples_leaf = 5, max_depth = 925,\\\n",
    "                            n_jobs=-1, random_state=29, bootstrap = True, verbose = 1)\n",
    "\n",
    "# Grid search on max_depth, min_samples_leaf\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "\n",
    "# n_splits is the number of times you split data after shuffling\n",
    "cv = ShuffleSplit(n_splits=1, test_size=1/5, random_state=4)\n",
    "\n",
    "# cv could be a fixed number of partitions but there would be no shuffling in that case\n",
    "# it will just rotate on partitions (k-1) parts and 1 part for cross-val\n",
    "rfr_grid = GridSearchCV(rfr, param_grid_rfr, cv=cv, scoring = 'neg_mean_squared_error', n_jobs = -1, verbose = 1)\n",
    "\n",
    "# run grid search, commented out to avoid accidental run\n",
    "# rfr_grid.fit(X,y)\n",
    "\n",
    "# Show winning parameters\n",
    "rfr_grid.best_estimator_\n",
    "# rfr_grid.best_params_\n",
    "# rfr_grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best score is the lowest MSE (averaged over Kfold cross-validation for each parameter value)\n",
    "print( 'MSE, best param, mean cross-val = {:.4f}'.format(-rfr_grid.best_score_) )\n",
    "print( 'RMSE, best param, mean cross-val = {:.4f}'.format(np.sqrt(-rfr_grid.best_score_)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions from rfr_grid, grid search refit rfr_grid on entire training set using best params\n",
    "y_pred_grid = rfr_grid.predict(X)\n",
    "# plot metrics on training set and compare to cross-validation metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('MSE (whole training set) = {:.4f}'.format(mean_squared_error(y, y_pred_grid)))\n",
    "print('RMSE (whole training set) = {:.4f}'.format(np.sqrt(mean_squared_error(y, y_pred_grid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tree is build on as many samples as the original training set (cannot change that setting\n",
    "unless you use Bagging class in sklearn).<br>\n",
    "\n",
    "Each tree is build by splitting node randomly. It ensures each tree is different (cannot change that setting unless you use Bagging class then decision tree default is 'best' for node spiltting) <br>\n",
    "\n",
    "The equivalent random forest can be achieved with bagging class:\n",
    "```Python\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "rfr = BaggingRegressor(\n",
    "                DecisionTreeRegressor(spiltter='random', min_samples_leaf = 5, max_depth = 900)\n",
    "                n_estimators = 10, max_samples = 1.0,\\\n",
    "                n_jobs = -1, , bootstrap = True, random_state = 29, verbose = 1)\n",
    "```\n",
    "\n",
    "One can enable bootstrap which samples training set with replacement thus adding extra randomness. (Increasing the number of tree is advised in that case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Random forest and cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators = 500,\\\n",
    "                            min_samples_leaf = 5, max_depth = 925,\\\n",
    "                            n_jobs = -1, random_state = 29, bootstrap = True, verbose = 1)\n",
    "\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "# n_splits is the number of times you split data after shuffling\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=4)\n",
    "\n",
    "# cv could be a fixed number of partitions but there would be no shuffling in that case\n",
    "# it will just rotate on partitions (k-1) parts and 1 part for cross-val\n",
    "cv_results_forest = cross_validate(rfr, X, y=y, cv=cv, scoring = 'neg_mean_squared_error', n_jobs = -1, verbose = 1)\n",
    "\n",
    "print('MSE (mean cross-validation) = {:.4f}'.format(-np.mean(cv_results_forest['test_score'])))\n",
    "print('RMSE (mean cross-validation) = {:.4f}'.format(np.sqrt(-np.mean(cv_results_forest['test_score']))))\n",
    "# Last results\n",
    "# 500 trees => RSME 2633.5295, 8h\n",
    "# 20 trees => RSME 2635.2640, 20 min \n",
    "# 10 trees => RSME 2637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:<br>\n",
    "Because bootstrap is True, there will be unused sample for each tree grown. Those are called Out-Of-Bag (OOB).Out-Of-Bag samples only tells you about the performance of each tree on aggregate and not on the entire random forest, it won't be a very good indicator as opposed to a proper cros-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train one decision tree on entire dataset, cross_validate does it on k-1 splits\n",
    "rfr.fit(X,y)\n",
    "\n",
    "# metrics on entire dataset, must be higher that Xval scores\n",
    "y_pred = rfr.predict(X)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('\\nMSE (whole training set) = {:.4f}'.format(mean_squared_error(y, y_pred)))\n",
    "print('RMSE (whole training set) = {:.4f}'.format(np.sqrt(mean_squared_error(y, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance is a measure of each feature efficiency of reduction in impurity weighted by the number of samples at each node. It is normalized by the sum of feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep matplotlib interactive\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "# use ggplot style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# feature importance shows Product categories are the best indicator followed by Product ID and user ID (barely)\n",
    "_, axrf = plt.subplots()\n",
    "axrf.plot(rfr.feature_importances_)\n",
    "# add title and axes labels\n",
    "axrf.set_title('Feature Importance')\n",
    "axrf.set_xlabel('Feature ')\n",
    "axrf.set_ylabel('Importance (Normalized)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(rfr, 'RandomForest_Model.pkl')\n",
    "\n",
    "# # example to load model\n",
    "# rfr = joblib.load('RandomForest_500_Model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test set in memory and recover encoders from file and derive one-hot encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import fextract as ft\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "filename = './test_HujdGe7/test.csv'\n",
    "df_test = pd.read_csv(filename)\n",
    "\n",
    "# Load encoders\n",
    "encoders = pickle.load( open( \"Onehotencoders.pkl\", \"rb\" ) )\n",
    "catcoders = pickle.load( open( \"Category_encoders.pkl\", \"rb\" ) )\n",
    "\n",
    "# reload is necessary if one makes changes in fextract. Indeed modules are loaded once only, this forces a reload.\n",
    "importlib.reload(ft)\n",
    "\n",
    "# get one-hot encoded features and their names\n",
    "features_test = ft.prepare_Data(df_test, (catcoders, encoders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select necessary features (must match your feature model obviously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features_test = tuple(f[0] for f in features_test if f[1] in imp_feature)\n",
    "X_test = hstack( X_features_test )\n",
    "# check shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions and save them to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = rfr.predict(X_test)\n",
    "\n",
    "# format result save to csv for submission\n",
    "df_results = df_test.loc[:,('User_ID','Product_ID')]\n",
    "df_results['Purchase'] = y_pred_test.reshape(-1,1)\n",
    "df_results.to_csv('Submission_RandomForest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
