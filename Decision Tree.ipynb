{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load features\n",
    "import pickle\n",
    "features = pickle.load( open( \"Onehotfeatures.pkl\", \"rb\" ) )\n",
    "\n",
    "# load associated targets\n",
    "from numpy import load\n",
    "y = load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose features and prepare data for scikit-learn prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep features of interest\n",
    "imp_feature = ['User_ID', 'Product_ID', 'Gender_Prod_cat123']\n",
    "# imp_feature = ['User_ID', 'Product_ID', 'Gender', 'Prod_cat123']\n",
    "# only keep corresponding features\n",
    "X_features = tuple(f[0] for f in features if f[1] in imp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550068, 9993), scipy.sparse.coo.coo_matrix)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X = hstack( X_features )\n",
    "X.shape, type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "Trying decision trees, very easy to overfit if you don't specify hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree - Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850 875 900 925 950 975]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    }
   ],
   "source": [
    "# DEFINE PARAMETER VALUES\n",
    "import numpy as np\n",
    "# depth_arr = np.array([ 10**x for x in range(2,4+1)])\n",
    "# depth_arr = np.array([ x for x in range(100,1000+100, 100)])\n",
    "depth_arr = np.array([ x for x in range(850,1000, 25)])\n",
    "# min_leaf_arr = np.array([ x+1 for x in range(0, 100+10, 10)])\n",
    "# min_leaf_arr[0]=1\n",
    "min_leaf_arr = np.array([ x for x in range(0, 20+1, 1)])\n",
    "min_leaf_arr = min_leaf_arr[1:]\n",
    "# print arrays\n",
    "print(depth_arr)\n",
    "print(min_leaf_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible order of tunning:\n",
    "1. max_depth and min_samples_leaf \n",
    "2. min_samples_split\n",
    "3. max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, best param, mean cross-val = 7021371.1369\n",
      "RMSE, best param, mean cross-val = 2649.7870\n",
      "{'max_depth': 875}\n"
     ]
    }
   ],
   "source": [
    "# instantiate decision tree model for regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(min_samples_leaf = 5, random_state = 29)\n",
    "\n",
    "# Grid search on max_depth, min_samples_leaf\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "# n_splits is the number of times you split data after shuffling\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=4)\n",
    "# cv could be a fixed number of partitions but there would be no shuffling in that case\n",
    "# it will just rotate on partitions (k-1) parts and 1 part for cross-val\n",
    "# param_grid_tree = [{'max_depth': depth_arr, 'min_samples_leaf': min_leaf_arr }]\n",
    "param_grid_tree = [{'max_depth': depth_arr}]\n",
    "tree_reg_grid = GridSearchCV(tree_reg, param_grid_tree, cv=cv,\\\n",
    "                          scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# run grid search\n",
    "tree_reg_grid.fit(X,y)\n",
    "\n",
    "# best of mean test score\n",
    "print( 'MSE, best param, mean cross-val = {:.4f}'.format(-tree_reg_grid.best_score_) )\n",
    "print( 'RMSE, best param, mean cross-val = {:.4f}'.format(np.sqrt(-tree_reg_grid.best_score_)) )\n",
    "\n",
    "# # Corresponding TRAIN score (subset)\n",
    "# print( '\\nMSE, best param, mean training set = {:.4f}'.format(\\\n",
    "#                                     min(-tree_reg_grid.cv_results_['mean_train_score']))) \n",
    "# print( 'RMSE, best param, mean training set = {:.4f}'.format(\\\n",
    "#                             np.sqrt(min(-tree_reg_grid.cv_results_['mean_train_score']))) )\n",
    "\n",
    "# optimal parameters: {'min_samples_leaf': 5, 'max_depth': 900}\n",
    "# finer search yields {'max_depth': 875}\n",
    "print(tree_reg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (mean cross-validation) = 7021443.8239\n",
      "RMSE (mean cross-validation) = 2649.8007\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "# instantiate decision tree model for regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor( min_samples_leaf = 5, max_depth = 900, random_state=29)\n",
    "\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "# n_splits is the number of times you split data after shuffling\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=4)\n",
    "# cv could be a fixed number of partitions but there would be no shuffling in that case\n",
    "# it will just rotate on partitions (k-1) parts and 1 part for cross-val\n",
    "cv_results_tree = cross_validate(tree_reg, X, y=y, cv=cv,\\\n",
    "                                 scoring = 'neg_mean_squared_error', n_jobs = -1)\n",
    "print('MSE (mean cross-validation) = {:.4f}'.format(-np.mean(cv_results_tree['test_score'])))\n",
    "print('RMSE (mean cross-validation) = {:.4f}'.format(np.sqrt(-np.mean(cv_results_tree['test_score']))))\n",
    "# RMSE (mean cross-validation) = 2649.8007\n",
    "\n",
    "# train one decision tree on entire dataset, cross_validate does it on k-1 splits\n",
    "tree_reg.fit(X,y)\n",
    "print('Training Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
