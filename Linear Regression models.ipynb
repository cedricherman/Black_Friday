{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data post feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load features\n",
    "# from scipy.sparse import load_npz\n",
    "# X = load_npz('features.npz')\n",
    "import pickle\n",
    "features = pickle.load( open( \"Onehotfeatures.pkl\", \"rb\" ) )\n",
    "# load associated targets\n",
    "from numpy import load\n",
    "y = load('target.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_ID', 'Product_ID', 'Gender', 'Marital_Status_Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Prod_cat123', 'Gender_Prod_cat123']\n"
     ]
    }
   ],
   "source": [
    "print([ f[1] for f in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep features of interest\n",
    "imp_feature = ['User_ID', 'Product_ID', 'Gender_Prod_cat123']\n",
    "# only keep corresponding features\n",
    "X_features = tuple(f[0] for f in features if f[1] in imp_feature)\n",
    "\n",
    "# X_features_filt = tuple( X_features[i]  for i,f in enumerate(feature_names) if f in imp_feature )\n",
    "## Alternative: unpack via list of indices\n",
    "# from operator import itemgetter\n",
    "# %timeit itemgetter(*[i  for i,f in enumerate(feature_names) if f in imp_feature])(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550068, 9993), scipy.sparse.coo.coo_matrix)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X = hstack( X_features )\n",
    "X.shape, type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "Scikit-learn implements the closed-form version: $$ \\hat{\\theta} = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$$ \n",
    "Model parameters are optimal (i.e. there is no gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# fit_intercept=True adds bias/intercept so that we don't have to worry about it.\n",
    "# n_jobs doesn't speed up because I only have one target (Purchase)\n",
    "model = LinearRegression(n_jobs=-1, normalize=False, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cross validation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (mean cross-validation) = 6283021.9802\n",
      "RMSE (mean cross-validation) = 2506.5957\n"
     ]
    }
   ],
   "source": [
    "# report score on cross-validation\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "# n_splits is the number of times you split data after shuffling\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=4)\n",
    "\n",
    "# cv could be a fixed number of partitions but there would be no shuffling in that case\n",
    "# it will just rotate on partitions (k-1) parts and 1 part for cross-val\n",
    "cv_results_linear = cross_validate(model, X, y=y, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# plot metrics\n",
    "import numpy as np\n",
    "MSE_Xval = -np.mean(cv_results_linear['test_score'])\n",
    "print('MSE (mean cross-validation) = {:.4f}'.format(MSE_Xval))\n",
    "print('RMSE (mean cross-validation) = {:.4f}'.format(np.sqrt(MSE_Xval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run model on entire training set and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (whole training set) = 6017192.8707\n",
      "RMSE (whole training set) = 2452.9967\n"
     ]
    }
   ],
   "source": [
    "# train one more time on all instances\n",
    "model.fit(X,y)\n",
    "\n",
    "# get predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# plot metrics on training set and compare to cross-validation metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('MSE (whole training set) = {:.4f}'.format(mean_squared_error(y, y_pred)))\n",
    "print('RMSE (whole training set) = {:.4f}'.format(np.sqrt(mean_squared_error(y, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Am I overfitting (high variance)? underfitting? (high bias)\n",
    "\n",
    "There is a gap of about 100 RSME which is small compared to our 2500 RSME of our model but it does indicates our variance is a little elevated. Consider using ridge regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def plot_learning_curve(model,X,y):\n",
    "    # split data/target in train and test sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    train_errors, val_errors = [], []\n",
    "    train_sizes = np.linspace(1, X_train.shape[0], 100, dtype='int64')\n",
    "    for m in train_sizes:\n",
    "        # train with m samples\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        # predict training data and val data\n",
    "        y_train_pred = model.predict(X_train[:m])\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        # save MSE metric\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_pred))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_pred))\n",
    "    _ , ax = plt.subplots()\n",
    "    ax.plot(train_sizes, np.sqrt(train_errors), 'r-+', linewidth=2, label='train')\n",
    "    ax.plot(train_sizes, np.sqrt(val_errors), 'b-', linewidth=2, label='validation')\n",
    "\n",
    "plot_learning_curve(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples where the error is very large or very low\n",
    "Best and worst example have the same magnitude! (1e-8 to 1e8 error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# square error, ascending order\n",
    "sqerr_asc = np.sort((y-y_pred)**2)\n",
    "\n",
    "# read dataframe post feature extraction\n",
    "\n",
    "# At square_error = 5e7, error rises dramatically\n",
    "df_worst = df.loc[sqerr_asc > 5e7, :].copy()\n",
    "\n",
    "# look at a few examples\n",
    "df_worst.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_rare_cases(Rare):\n",
    "    Rare_HighErr = df_worst[Rare.name].isin(Rare.index).sum()\n",
    "    print( 'Number of rare {} having high error = {} out of {} ({:.2f}%)'.format(\\\n",
    "    Rare.name, Rare_HighErr, Rare.count(), Rare_HighErr/Rare.count()*100) )\n",
    "\n",
    "# Almost None of the rare product ID corresponds to the worst cases\n",
    "RareProdID = ProdID_distrib[ProdID_distrib < 5]\n",
    "print_rare_cases(RareProdID)\n",
    "# what about rare users?\n",
    "# rare user is defined as less than 10-16 occurrence (see distribution of users)\n",
    "RareUsers = UserID_distrib[UserID_distrib < 16]\n",
    "print_rare_cases(RareUsers)\n",
    "# what about Prod cat123?\n",
    "RareProdCat123 = ProdCat_distrib[ProdCat_distrib < 100]\n",
    "print_rare_cases(RareProdCat123)\n",
    "\n",
    "# print total number identified as high error\n",
    "print('Number of worst instances = {}'.format(df_worst.Purchase.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make plots for each features from worst subset\n",
    "cat_list = ['Gender', 'Age', 'Occupation',\\\n",
    "            'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
    "_ , axw = plt.subplots(3, 2)\n",
    "axw = axw.flatten()\n",
    "# for k in range(len(df_worst.columns)-1):\n",
    "for k, colname in enumerate(cat_list):\n",
    "    dis = df_worst.loc[:, colname]\n",
    "    dis.value_counts().plot(kind='bar', ax=axw[k])\n",
    "    axw[k].set_title(dis.name)\n",
    "plt.tight_layout()\n",
    "\n",
    "_ , axw2 = plt.subplots()\n",
    "# value_counts() sort value in descending order by default\n",
    "UserWorst_distrib = df_worst.loc[:, 'User_ID'].value_counts()\n",
    "# UserWorst_distrib.plot(kind='bar', ax=axw2)\n",
    "axw2.plot(range(UserWorst_distrib.count()) , UserWorst_distrib.values)\n",
    "axw2.set_title(df_worst.User_ID.name)\n",
    "\n",
    "_ , axw3 = plt.subplots()\n",
    "ProdIDWorst_distrib = df_worst.Product_ID.value_counts()\n",
    "# ProdIDWorst_distrib.plot(kind='bar', ax=axw3)\n",
    "axw3.plot(range(ProdIDWorst_distrib.count()) , ProdIDWorst_distrib.values)\n",
    "axw3.set_title(df_worst.Product_ID.name)\n",
    "\n",
    "_ , axw4 = plt.subplots()\n",
    "ProdCatWorst_distrib = df_worst.Prod_cat123.value_counts()\n",
    "# ProdCatWorst_distrib.plot(kind='bar', ax=axw4)\n",
    "axw4.plot(range(ProdCatWorst_distrib.count()) , ProdCatWorst_distrib.values)\n",
    "axw4.set_title(df_worst.Prod_cat123.name)\n",
    "\n",
    "_ , axsq = plt.subplots()\n",
    "axsq.plot(sqerr_asc)\n",
    "axsq.set_title('Error Per Sample vs Sample Index')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
